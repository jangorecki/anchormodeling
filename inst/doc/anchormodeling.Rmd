
# Guide on Anchor Modeling in R

You should have already installed [anchormodeling](https://github.com/jangorecki/anchormodeling) R package. For configuring fresh linux environment see [Setup Guide](setup.md).  

## Define domain

Inside the package there is already working example model for *Stage performances* domain, see `?actor.am`, `?actor.data` to populate model/data.  

In this document I will define basic model for git repository data.  
You can use git's *traveling in time* ability to easily produce data which evolves over time.  
You can follow example locally on your machines.  

## Extract data from git

In the working directory create subdir for git clone your repo.  
I will use [bitcoin](https://github.com/bitcoin/bitcoin) repo as it is a good example of distributed project: 300 contributors, 8400 commits, 4000 pull requests.

You can use shell script to generate source data directly from git repo.  
Limited by `--before="2014-01-01"`.   

```sh
mkdir wd
cd wd
git clone https://github.com/bitcoin/bitcoin
cd bitcoin
# modified https://gist.github.com/textarcana/1306223
git log \
    --before="2014-01-01" \
    --pretty=format:'{%n  "commit": "%H",%n  "author": "%an",%n  "author_email": "%ae",%n  "timestamp": "%at",%n  "message": "%f"%n},' \
    $@ | \
    perl -pe 'BEGIN{print "["}; END{print "]\n"}' | \
    perl -pe 's/},]/}]/' > ../commits2013.json
```

In new session navigate to your `wd` directory and run R.    

```sh
R
```

Source data *json* files are ready to be picked up.  
Can be easiy loaded using [jsonlite](https://github.com/jeroenooms/jsonlite).  

```{r extract_commits}
library(devtools)
load_all("anchormodeling")
#library(anchormodeling)
library(jsonlite)
extract.commits <- function(x){
    char_cols <- c("commit","author","author_email","message") # handle encoding
    setDT(fromJSON(x))[, `:=`(timestamp = as.POSIXct(as.integer(timestamp), origin="1970-01-01"))
                       ][, c(char_cols) := lapply(.SD, function(x) {Encoding(x) <- "unknown"; x}), .SDcols = char_cols]
}
```

## Define Anchor Model

```{r model}
am <- AM$new()
am$add$A(mne = "AU", desc = "Author")
am$add$a(mne = "NAM", desc = "Name", hist = TRUE, anchor = "AU")
am$add$a(mne = "EMA", desc = "Email", anchor = "AU")
# am$add$A(mne = "BR", desc = "Branch")
am$add$A(mne = "CM", desc = "Commit")
am$add$a(mne = "TIM", desc = "Time", anchor = "CM")
am$add$a(mne = "MES", desc = "Message", anchor = "CM")
am$add$a(mne = "TAG", desc = "Tag", anchor = "CM")
am$add$a(mne = "HSH", desc = "Hash", anchor = "CM")
am$add$t(anchors = c("AU","CM"), roles = c("authoring","of"), identifier = c(1,Inf))
am$validate()
```

## Run AM Data Warehouse instance

```{r run}
am$run()
```

## Load data to DW

You need to define mapping.  
Each symbol nested in below list substitutes the character scalar provided by user while defining mapping.  

```r
mapping <- list(anchor1_mne = list(natural_key_column_names,
                                   attr1_mne = column_name,
                                   attr2_mne = c(column_name, "hist" = historize_column_name),
                                   attr3_mne = c(column_name, "knot" = knot_mne),
                                   attr3_mne = c(column_name, "hist" = historize_column_name, "knot" = knot_mne)),
                anchor2_mne = list(natural_key_column_names,
                                   attr1_mne = column_name,
                                   attr2_mne = c(column_name, "hist" = historize_column_name),
                                   attr3_mne = c(column_name, "knot" = knot_mne),
                                   attr3_mne = c(column_name, "hist" = historize_column_name, "knot" = knot_mne)))
```

On our simple git repo data model.

```{r mapping}
mapping <- list(CM = list("commit",
                          MES = "message",
                          TIM = "timestamp",
                          HSH = "commit"),
                AU = list("author_email", # natural key
                          NAM = c("author", hist = "timestamp"),
                          EMA = "author_email"))
```

`meta` argument is used as processing batch metadata. Can be integer `meta` or list, see example.  

```{r load}
commits1 <- extract.commits("commits2013.json")
am$load(mapping, commits1, meta = 1L)
am$load(mapping, commits1, meta = list(meta = 2L, user = "manual", src = "git log")) # log custom details
```

Duplicate inserts were handled automatically.  
To controling temporal duplicates use *restatement* feature when create *attributes*/*knots* by `rest = FALSE` argument or at start `options("am.restatability" = FALSE)` globally.  

## Query data

3NF are not yet ready.  

```{r view}
# am$view("AU")
am$view("AU", type = "current")
am$view("AU", type = "latest")
am$view("AU", type = "timepoint", timepoint = as.POSIXct("2012-01-01 00:00:00", origin="1970-01-01"))
am$view("AU", type = "difference", timepoint = c(as.POSIXct("2012-01-01 00:00:00", origin="1970-01-01"), as.POSIXct("2012-02-01 00:00:00", origin="1970-01-01")))
```

## Query metadata

Check all the below commands.

```{r status_initial_load}
am
am$etl # you should notice your OS user name on `meta==1L`
am$log
am$IM()
```

## Save AM instance

```{r stop}
am$stop()
save(am, mapping, extract.commits, file = "git-am.RData")
# loading
load("git-am.RData")
am$run()
```

Loading anchor model from the *RData* was not yet tested.

## Export model

```{r xml}
am$xml()
```

File can be loaded in official Anchor Modeler Test: [roenbaeck.github.io/anchor](http://roenbaeck.github.io/anchor/)  
After loading xml file don't forget to click *Play* button.  
Exported xml does not contain non-model fields like data types. Also it won't export restatability definition as it is part of metadata of model in current XML schema. This may be subject to change in Anchor Modeling, see [anchor#4](https://github.com/Roenbaeck/anchor/issues/4).  

Current model can look like that.  

![Git repo AM first iteration](git-am1.png)

If you don't like how your model looks like you can use *Layout* menu and *Release all fixed* or *Randomize layout* options.  

## Incremental loading

Produce new batch of data from git repo.  
Limited by `--before="2015-01-01"`. Duplicates handled.  

```sh
git log \
    --before="2015-01-01" \
    --pretty=format:'{%n  "commit": "%H",%n  "author": "%an",%n  "author_email": "%ae",%n  "timestamp": "%at",%n  "message": "%f"%n},' \
    $@ | \
    perl -pe 'BEGIN{print "["}; END{print "]\n"}' | \
    perl -pe 's/},]/}]/' > ../commits2014.json
```

Go back to R.

```{r incremental_load}
commits2 <- extract.commits("commits2014.json")
am$load(mapping, commits2, meta = list(meta = 3L, src = "git log"))
```

```{r status_incremental_load}
am
am$etl
am$log
am$IM()
```

## Evolving model

Add individual file insertions/deletions details - `git log --numstat`.  

```sh
git log \
    --before="2015-01-01" \
    --numstat \
    --format='%H' \
    $@ | \
    perl -lawne '
        if (defined $F[1]) {
            print qq#{"insertions": "$F[0]", "deletions": "$F[1]", "path": "$F[2]"},#
        } elsif (defined $F[0]) {
            print qq#],\n"$F[0]": [#
        };
        END{print qq#],#}' | \
    tail -n +2 | \
    perl -wpe 'BEGIN{print "{"}; END{print "}"}' | \
    tr '\n' ' ' | \
    perl -wpe 's#(]|}),\s*(]|})#$1$2#g' | \
    perl -wpe 's#,\s*?}$#}#' > ../numstats2014.json
```

```{r extract_numstats}
extract.numstats <- function(x){
    char_cols <- c("commit","path") # handle encoding
    rbindlist(fromJSON(x), idcol = "commit")[insertions=="-", insertions := NA_character_
                                             ][deletions=="-", deletions := NA_character_
                                               ][, `:=`(insertions=as.integer(insertions), deletions=as.integer(deletions))
                                                 ][, c(char_cols) := lapply(.SD, function(x) {Encoding(x) <- "unknown"; x}), .SDcols = char_cols]
}
```

```{r evolve_model}
am$add$A(mne = "FI", desc = "File")
am$add$a(mne = "PAT", desc = "Path", anchor = "FI")
am$add$a(mne = "INS", desc = "Insertions", anchor = "FI")
am$add$a(mne = "DEL", desc = "Deletions", anchor = "FI")
am$add$t(anchors = c("FI","CM"), roles = c("changed","in"), identifier = c(Inf,Inf))
am$validate()
mapping.numstat <- list(FI = list(c("commit","path"),
                                  PAT = "path",
                                  INS = "insertions",
                                  DEL = "deletions"))
am$run()
```

```{r evolved_load}
numstats1 <- extract.numstats("numstats2014.json")
am$load(mapping.numstat, numstats1, meta = list(meta = 4L, src = "git log"))
```

```{r evolved_view}
# am$view()
```

```{r status_evolved_load}
am
am$etl
am$log
am$IM()
```

## Questions

- Why it is so fast?  

[data.table](https://github.com/Rdatatable/data.table) design assumes from the early days to handle time series data well.  

> fast joins  
> fast rolling joins  
> fast overlaping joins (range)  

All of them are going to be employed in R session memory AM instance.  
You can use your favorite data analysis packages on top of AM 3NF views.  

- How to start?

Model any data, your model can non-destructivly grow over time so you can think about it later!  
In this doc you have example on loading git repo data, apply it on some other repo.  
If you have some DWH data already, you can just use a minimal subset of it.  

- Stability of project?

In development, ready for testing.  
You are welcome to add your unit tests which can be included in automated unit testing on package build.  

- Waiting for more questions to add here

## Importants notes vs SQL anchor model

- data stored in-memory
- built-in ETL
- triggers are replaced by functions
- built-in Identity Management
- built-in dashboard
- high performance data processing using [data.table](https://github.com/Rdatatable/data.table)
- does not support *concurrent-reliance-temporal*
- easy multiple AM instances in R session
